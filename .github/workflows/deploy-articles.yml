# =============================================================================
# Simorgh Articles - Auto Summarize & Deploy to VPS
# =============================================================================
# Triggers on push to main when articles/ directory changes.
# For each article directory:
#   1. Reads meta.json to find PDF filenames (or falls back to en.pdf/fa.pdf)
#   2. Extracts text from PDFs using PyMuPDF
#   3. Calls OpenAI API to generate concise summaries
#   4. Writes summary_en.txt and summary_fa.txt
#   5. Builds articles.json manifest
#   6. Deploys everything to VPS at /opt/simorgh-articles/
# =============================================================================
#
# Required repository secrets:
#   OPENAI_API_KEY       - OpenAI API key for generating summaries
#   VPS_SSH_PRIVATE_KEY  - SSH private key for VPS access (PEM format)
#   VPS_USER             - SSH username on VPS (e.g., shm)
#   VPS_HOST             - VPS IP address or hostname
# =============================================================================

name: Deploy Articles

on:
  push:
    branches: [main]
    paths:
      - 'articles/**'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  summarize-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install openai PyMuPDF

      - name: Generate summaries and build manifest
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python3 << 'PYEOF'
          import os, json, glob
          import fitz  # PyMuPDF
          from openai import OpenAI

          client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
          articles_dir = "articles"
          manifest = []

          def extract_pdf_text(pdf_path):
              text = ""
              with fitz.open(pdf_path) as doc:
                  for page in doc:
                      text += page.get_text()
              return text.strip()

          def get_summary(text, language):
              lang_label = "English" if language == "en" else "Persian (Farsi)"
              if len(text) > 12000:
                  text = text[:12000] + "\n...[truncated]"
              try:
                  response = client.chat.completions.create(
                      model="gpt-4o-mini",
                      messages=[
                          {
                              "role": "system",
                              "content": f"You are a helpful assistant. Provide a concise summary (2-3 sentences) of the following article in {lang_label}. Return ONLY the summary text, nothing else."
                          },
                          {"role": "user", "content": text}
                      ],
                      max_tokens=300,
                      temperature=0.3
                  )
                  return response.choices[0].message.content.strip()
              except Exception as e:
                  print(f"  Warning: OpenAI API error for {lang_label}: {e}")
                  return text[:200].rsplit(' ', 1)[0] + "..." if text else "Summary not available"

          for article_dir in sorted(glob.glob(f"{articles_dir}/*/")):
              slug = os.path.basename(article_dir.rstrip('/'))
              print(f"Processing: {slug}")

              meta_path = os.path.join(article_dir, "meta.json")
              meta = {"title_en": slug, "title_fa": slug, "author": "", "date": "", "tags": []}
              if os.path.exists(meta_path):
                  with open(meta_path, 'r', encoding='utf-8') as f:
                      meta.update(json.load(f))

              # Resolve PDF filenames: meta.json files > en.pdf/fa.pdf fallback
              files_conf = meta.get("files", {})
              en_filename = files_conf.get("en", "en.pdf")
              fa_filename = files_conf.get("fa", "fa.pdf")
              en_path = os.path.join(article_dir, en_filename)
              fa_path = os.path.join(article_dir, fa_filename)

              # Find PDFs in directory
              all_pdfs = glob.glob(os.path.join(article_dir, "*.pdf"))
              if not all_pdfs:
                  print(f"  Skipping {slug}: no PDF files found")
                  continue

              en_exists = os.path.exists(en_path)
              fa_exists = os.path.exists(fa_path)

              if not en_exists and not fa_exists:
                  print(f"  Warning: configured PDFs not found, using first available")
                  en_path = all_pdfs[0]
                  en_filename = os.path.basename(en_path)
                  en_exists = True
                  if len(all_pdfs) > 1:
                      fa_path = all_pdfs[1]
                      fa_filename = os.path.basename(fa_path)
                      fa_exists = True

              # Extract text
              en_text = ""
              fa_text = ""
              if en_exists:
                  print(f"  Extracting text from {en_filename}...")
                  en_text = extract_pdf_text(en_path)
                  if not en_text:
                      print(f"  Warning: No text extracted from {en_filename}")
              if fa_exists:
                  print(f"  Extracting text from {fa_filename}...")
                  fa_text = extract_pdf_text(fa_path)
                  if not fa_text:
                      print(f"  Warning: No text extracted from {fa_filename}")

              # Generate summaries
              summary_en = get_summary(en_text, "en") if en_text else meta.get("title_en", slug)
              summary_fa = get_summary(fa_text, "fa") if fa_text else meta.get("title_fa", slug)

              summary_en_path = os.path.join(article_dir, "summary_en.txt")
              summary_fa_path = os.path.join(article_dir, "summary_fa.txt")
              with open(summary_en_path, 'w', encoding='utf-8') as f:
                  f.write(summary_en)
              with open(summary_fa_path, 'w', encoding='utf-8') as f:
                  f.write(summary_fa)

              print(f"  EN summary: {summary_en[:80]}...")
              print(f"  FA summary: {summary_fa[:80]}...")

              manifest.append({
                  "slug": slug,
                  "title_en": meta.get("title_en", slug),
                  "title_fa": meta.get("title_fa", slug),
                  "summary_en": summary_en,
                  "summary_fa": summary_fa,
                  "author": meta.get("author", ""),
                  "date": meta.get("date", ""),
                  "tags": meta.get("tags", []),
                  "files": {
                      "en": f"{slug}/{en_filename}",
                      "fa": f"{slug}/{fa_filename}" if fa_exists else f"{slug}/{en_filename}"
                  }
              })

          manifest_path = os.path.join(articles_dir, "articles.json")
          with open(manifest_path, 'w', encoding='utf-8') as f:
              json.dump(manifest, f, ensure_ascii=False, indent=2)

          print(f"\nManifest written with {len(manifest)} article(s)")
          PYEOF

      - name: Commit summaries and manifest
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          git add articles/
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Auto-generate article summaries and manifest [skip ci]"
            git push
          fi

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.VPS_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          # Accept the VPS host key automatically
          ssh-keyscan -H "${{ secrets.VPS_HOST }}" >> ~/.ssh/known_hosts 2>/dev/null || true
          # Verify the key was written
          echo "SSH key fingerprint:"
          ssh-keygen -l -f ~/.ssh/id_rsa || echo "WARNING: SSH key may be invalid"

      - name: Deploy articles to VPS
        run: |
          VPS_USER="${{ secrets.VPS_USER }}"
          VPS_HOST="${{ secrets.VPS_HOST }}"
          REMOTE_DIR="/opt/simorgh-articles"

          if [ -z "$VPS_USER" ] || [ -z "$VPS_HOST" ]; then
            echo "ERROR: Missing VPS_USER or VPS_HOST secret"
            echo "Please add these secrets in GitHub repo Settings > Secrets"
            exit 1
          fi

          echo "Deploying to ${VPS_HOST}:${REMOTE_DIR}"

          # Create remote directory and ensure the deploy user owns it
          ssh -o StrictHostKeyChecking=accept-new \
              "${VPS_USER}@${VPS_HOST}" \
              "sudo mkdir -p ${REMOTE_DIR} && sudo chown -R ${VPS_USER}:${VPS_USER} ${REMOTE_DIR}"

          # Sync articles directory to VPS
          rsync -avz --delete \
            -e "ssh -o StrictHostKeyChecking=accept-new" \
            articles/ \
            "${VPS_USER}@${VPS_HOST}:${REMOTE_DIR}/"

          echo "Articles deployed successfully"

      - name: Restart nginx on VPS
        run: |
          VPS_USER="${{ secrets.VPS_USER }}"
          VPS_HOST="${{ secrets.VPS_HOST }}"

          # Restart nginx so it picks up the new articles volume
          ssh -o StrictHostKeyChecking=accept-new \
              "${VPS_USER}@${VPS_HOST}" \
              "cd /opt/simorghai-vps && docker compose restart nginx-proxy || true"

          echo "Nginx restarted"
